# 城市漂流：开发文档

## 核心概念与术语
- 探索会话 (Exploration Session): 指用户从点击“开始探索”到“结束探索”的单次连续旅程。它是所有相关数据（如路径、互动、情感等）的主要容器。
- AI 指令 (AI Instruction): 由 AI 核心生成的实时、情境感知的引导性提示。指令是动态的，会受到用户位置、过往互动和当前情感状态的综合影响。
- 互动事件 (Interaction Event): 由用户或 AI 发起的、涉及多模态数据采集的离散事件。类型包括：语音记录（用户说话）、图像捕捉（用户拍照）和主动询问（AI 提问）。
- 情感状态 (Emotional State): 一个用于表示用户在特定时间点或路径段上推断出的情感状况的数据结构。该数据将由 AI 负责人开发的多层次情感分析模型生成（例如，使用效价-唤醒度维度或分类情感标签）。
- 情感地图 (Emotion Map): 探索会话结束后的总结性可视化界面。它由一个包含用户 GPS Path 的基础地图层、一个由 Emotional Segments（情感分段，以颜色编码）组成的叠加层，以及在重要 Interaction Events（互动事件）位置上标记的交互式 Highlight Nodes（高亮节点）构成。

## 系统架构
系统由四个主要部分构成，它们的协同工作构成了应用的核心功能。

- 移动应用 (客户端): 这是直接面向用户的应用程序（支持 iOS/Android）。它负责处理用户界面、传感器数据收集（GPS、麦克风、摄像头），以及与后端系统的通信。
- 后端系统 (API & 数据库): 作为系统的中枢神经。它负责处理用户认证、数据持久化、业务逻辑，并充当客户端与 AI 核心之间的代理。
- AI 核心 (算法服务): 这是应用的“大脑”，由 AI 负责人管理。它可能是一组微服务或一个单一服务，专门负责：
    - 多层次情感分析（处理音频/图像数据）。
    - 情境化指令生成。
- 外部服务: 项目依赖的第三方服务。(可选)
    - 地图服务: 例如 高德地图 API 或 Google Maps API，用于提供底图瓦片和可能的逆地理编码功能。
    - 云存储: 用于存储原始媒体文件（音频、图像）。
    - 语音转文本服务 (可选/初期): 例如 Google Speech-to-Text，用于将用户语音转录为文本以供分析，后期可能被定制模型取代。

系统的运行模式是一个实时的、有状态的对话代理，这要求后端架构比简单的 CRUD（增删改查）应用更为复杂。用户流程图（生成指令 -> 响应用户 -> 生成指令）和 AI 主动交互的设定，意味着一个持续的反馈循环。为了生成下一条相关的指令，AI 核心需要当前会话的完整上下文：用户去过哪里、说过什么、近期的情感轨迹等。这意味着后端不能是无状态的。它必须为每个活跃的探索会话维护一个“会话上下文”。这强烈建议使用像 Redis 这样的内存缓存来存储此会话状态，以实现指令生成时的低延迟访问，并将其与主数据库中的长期存储分离开。这对全栈开发人员来说，是一个至关重要的架构决策。

## 详细功能规格与用户流程
UI设计还未完成，原型在[Figma](https://www.figma.com/design/olFAOVNiv58wifJ5u3pZnk/%E5%8E%9F%E5%9E%8B?node-id=0-1&m=dev)里。主要界面有下面三个：

1. 用户引导与首页
- 用户流程:
    - 首次启动：应用展示闪屏，随后是一个简短的引导轮播页，解释应用的核心理念（例如，“你的城市，你的感受，为每一种心情绘制一张新地图”）。
    - 权限请求：一个清晰的页面，集中请求必要的权限：位置（始终允许，用于后台追踪）、麦克风和摄像头。必须附上简洁的解释，说明为何需要每项权限，以建立用户信任。
    - 用户认证：提供简单的邮箱/密码注册与登录功能，并支持社交登录（如 Google、Apple），以减少用户操作阻力。
- 首页 UI/UX:
    - 主视图: 一个按时间倒序排列的、可滚动的过往“探索轨迹”列表。每个条目应设计成一个视觉上吸引人的卡片，可以展示情感地图的缩略图、日期、时长以及一个用户可编辑的标题（例如，“老城区的雨后午后”）。
    - 核心操作 (CTA): 一个醒目的“开始新的探索”按钮。
    - 次要元素: 提供用户个人资料的入口，并展示游戏化元素（如积分、等级、获得的徽章）。

2. “探索中”体验
- 用户流程:
    1. 用户点击“开始新的探索”，应用切换至探索界面。
    2. AI 核心生成并显示第一条指令。
    3. 用户开始移动，应用在后台持续追踪其位置。
    4. 用户可随时使用多模态按钮进行互动（点击录制语音，点击打开相机）。
    5. AI 可能会主动发起提示（例如，“你的速度慢下来了，是什么吸引了你的注意？”）。
    6. （移动 -> 指令 -> 互动）的循环持续进行。
    7. 用户点击“结束探索”按钮，确认后进入总结页面。
- 探索界面 UI/UX:
    - 顶部 10%: 极简的状态指示器（如已用时间、已走距离）。
    - 中间 40%: 指令显示区。使用干净、大号、清晰的字体展示 AI 指令。
    - 底部 50%: 多模态互动面板。
- 核心逻辑:
    - 后台位置追踪: 这是一个关键的技术挑战。该服务必须稳定、省电，并且在应用退至后台时也能持续运行。
    - 主动互动触发器: 后端将通过一个信号（例如，WebSocket 或定期轮询）通知客户端触发一个主动提示。触发条件可以基于：用户速度变化（通过 GPS 数据检测）、进入预定义的兴趣点区域，或检测到显著的情感转变。

探索中的用户界面设计必须将“沉浸感”置于“信息密度”之上，使其成为连接现实世界的最小化接口。应用的核心价值在于体验物理城市。一个充满过多文字或按钮的杂乱界面会分散用户的注意力，将他们从真实环境中拉回到手机屏幕上。这意味着设计必须奉行极简主义。互动按钮需要足够大，以便用户无需注视即可轻松操作。AI 的主动提示也必须谨慎处理——一个突兀的通知可能会打破用户的沉浸感。这提示我们可以探索非视觉的反馈方式，如通过耳机传递的微妙震动或音频提示，作为 AI 发起互动的更少侵入性的方式。

3. “情感地图”与探索后总结
- 用户流程:
    - 结束探索后，显示一个加载/处理界面，并附上“正在生成您的情感地图…”之类的提示信息。
    - 总结页面出现，以情感地图为核心元素。
    - 用户可以平移、缩放和与地图互动。点击高亮节点会弹出相关联的媒体（播放音频片段、显示照片）和 AI 的分析结果。
    - 用户可以为本次探索命名，并分享一张总结图片。
- 情感地图 UI/UX 可视化:
    - 路径层: 用户的 GPS 轨迹被绘制为一条折线 (Polyline)。
    - 情感层: 该折线根据每个路段的主导情感状态被分段并着色（例如，黄色代表喜悦，蓝色代表平静，红色代表兴奋）。应提供图例说明。
    - 互动层: 在发生 InteractionEvents 的精确坐标点上，放置可点击的小图标，展开可以显示分析。

从“探索中”到“总结”的过渡是数据合成和价值交付的关键时刻。用户刚刚投入了时间和精力完成一段旅程，情感地图的生成是他们获得的回报。一个漫长且不确定的加载屏幕会引发焦虑，并削弱最终的“惊艳”效果。这意味着生成总结的后端处理过程必须被高度优化。当用户看到加载界面时，后端正在执行一系列复杂的任务：整合所有 PathPoints，将 InteractionEvents 与最近的路径段关联，对整个会话进行最终的情感分析，并将这些数据打包成一个干净的载荷（payload）返回给客户端。这个过程应在后端设计为一个异步任务，以避免阻塞服务器。客户端可以轮询一个端点来检查任务状态，直到总结数据准备就绪。

## 技术架构与数据模型
1. 前端架构
- 推荐技术栈: React Native。这允许从单一代码库进行跨平台开发，对于一个两人团队至关重要。具体选择取决于全栈开发人员现有的技术专长。
- 状态管理: 需要一个强大的状态管理库（例如，React Native 的 Redux Toolkit）来管理复杂的应用状态，尤其是在活跃的探索会话期间（如追踪状态、指令等）。
- 关键模块/集成:
    - 后台地理定位: 一个高度可靠的库（如 react-native-background-geolocation）是不可或缺的。必须对其进行配置，以在电池寿命和定位精度之间取得最佳平衡。
    - 媒体处理: 用于音频录制 (react-native-voice) 和相机访问 (react-native-camera) 的库。
    - 离线缓存: 应用必须能够应对间歇性的网络中断。位置数据和互动事件应在本地进行缓存（例如，使用 SQLite 或 AsyncStorage），并在网络连接恢复后与后端同步。

2. 后端架构
- 推荐技术栈: Python 及其现代框架，如 FastAPI 或 Flask。Python 强大的数据科学和机器学习生态系统使其成为与 AI 核心无缝集成的自然选择。FastAPI 提供高性能和自动化的 API 文档，这是一个显著的优势。
- 可以先试一下Supabase，部署地域似乎只能选择韩国，日本，新加坡，印度等亚洲地区，不清楚在国内的访问速度怎么样。

3. AI 核心集成策略
通过一个私有的 REST API 暴露给后端系统。
- 同步流程 (用于获取指令):
    - 客户端向后端请求新指令。
    - 后端从 Redis 缓存中检索当前会话的上下文。
    - 后端向 AI 核心的 /generate_instruction 端点发起一个同步 API 调用，并传递会话上下文。
    - AI 核心返回指令文本。
    - 后端将指令转发给客户端。

- 异步流程 (用于情感分析):
    - 客户端将 InteractionEvent 中的媒体文件（音频/图像）上传到后端。
    - 后端将原始文件保存到云存储（如 S3），并在数据库中创建一个状态为“处理中”的 InteractionEvent 记录。
    - 后端将一个包含文件位置和事件 ID 的任务推送到 Celery 任务队列。
    - 一个 Celery worker 获取该任务，调用 AI 核心的 /analyze_emotion 端点，接收分析结果，并更新数据库中相应的 InteractionEvent 记录。

- 核心数据库模式，看这个[Google Sheet](https://docs.google.com/spreadsheets/d/1iU0sfeJkFcueXvYSY1tQoT-wDIUuRZsJQHNz2fb52AQ/edit?usp=sharing)

- API端点规格，看这个[Google Sheet](https://docs.google.com/spreadsheets/d/19mPDh3C4v-wdEMHxJWn5SdUsza_NooUtpgj2ZFK08uI/edit?usp=sharing)